{"/":{"title":"Introduction","data":{"":"카프카 핵심 개념들 요약 문서 페이지Examples\nkotlin version : example-kafka-kotlin\nspring-cloud-stream version : 준비 중\njava version : 준비 중"}},"/kafka-cli-examples":{"title":"Kafka CLI Examples","data":{"kafka-cli#Kafka CLI":""}},"/kafka-cli-examples/docker-compose":{"title":"Docker Compose","data":{"실습에서-사용할-docker-compose#실습에서 사용할 docker-compose":"실습에서 사용할 카프카 클러스터의 docker-compose 는 아래와 같습니다.\nversion: '2'\nservices:\n  zookeeper:\n    image: confluentinc/cp-zookeeper:latest\n    environment:\n      ZOOKEEPER_SERVER_ID: 1\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n      ZOOKEEPER_INIT_LIMIT: 5\n      ZOOKEEPER_SYNC_LIMIT: 2\n    ports:\n      - \"22181:2181\"\n  kafka:\n    image: confluentinc/cp-kafka:latest\n    depends_on:\n      - zookeeper\n    ports:\n      - \"29092:29092\"\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0","주의#주의":"실습에서 사용할 docker-compose exec 이라는 커맨드는 꼭 docker-compose.yml 파일이 위치해 있는 경로에서 실행해야 합니다. 그렇지 않으면 아래 에러가 발생합니다.\nno configuration file provided: not found"}},"/kafka-cli-examples/kafka-cli":{"title":"Kafka CLI","data":{"kafka-cli-실습---토픽-실습#Kafka CLI 실습 - 토픽 실습":"","topic-생성#topic 생성":"","single-partition-토픽-생성#single partition 토픽 생성":"topic 을 생성해봅니다. docker-compose 내의 kafka 라는 이름의 service 에 접속해서 topic1 을 생성하는 CLI 입니다.\n$ docker-compose exec kafka kafka-topics --create --topic topic1 --bootstrap-server kafka:29092\nCreated topic topic1.","partition-5-개-갖는-토픽-생성#partition 5 개 갖는 토픽 생성":"partition 을 5개 갖는 토픽을 생성합니다.\n$ docker-compose exec kafka kafka-topics --create --topic topic2 --bootstrap-server kafka:9092 --partitions 5\nCreated topic topic2.","partition-5개-replication-factor-1-인-토픽-생성#partition 5개, replication factor 1 인 토픽 생성":"이번에는 partition 의 갯수는 5개이면서 각각의 파티션이 1개씩 복제 되도록 replication factor 를 1 로 지정하는 토픽을 생성합니다.\n$ docker-compose exec kafka kafka-topics --create --topic topic3 --bootstrap-server kafka:9092 --partitions 5 --replication-factor 1\nCreated topic topic3.","토픽들을-출력list#토픽들을 출력(list)":"$ docker-compose exec kafka kafka-topics --list --bootstrap-server kafka:9092\ntopic1\ntopic2\ntopic3","토픽-describe#토픽 describe":"리눅스의 ls -al 명령처럼 현재 토픽들의 상세 상황을 살펴봅니다.\n$ docker-compose exec kafka kafka-topics --describe --topic topic2 --bootstrap-server kafka:9092\nTopic: topic2   TopicId: 8tbqDaMzSmWAvuHvwOGP5A PartitionCount: 5       ReplicationFactor: 1    Configs:\n        Topic: topic2   Partition: 0    Leader: 1       Replicas: 1     Isr: 1\n        Topic: topic2   Partition: 1    Leader: 1       Replicas: 1     Isr: 1\n        Topic: topic2   Partition: 2    Leader: 1       Replicas: 1     Isr: 1\n        Topic: topic2   Partition: 3    Leader: 1       Replicas: 1     Isr: 1\n        Topic: topic2   Partition: 4    Leader: 1       Replicas: 1     Isr: 1","토픽-삭제#토픽 삭제":"토픽 삭제는 아래와 같이 해줄수 있습니다.\n$ docker-compose exec kafka kafka-topics --delete --topic topic1 --bootstrap-server kafka:9092","카프카-프로듀서-cli#카프카 프로듀서 CLI":"카프카 프로듀서 CLI 는 docker-compose 안으로 직접 진입해야만 접근이 가능합니다.\n$ docker-compose exec kafka bash\nCLI 에서 사용자의 입력을 받는 producer 를 console-producer 라고 하며, 카프카를 직접 zip 파일로 다운받아보면 그 곳에 producer, consumer 등의 쉘스크립트가 있는데, 이 것들을 보통 콘솔 프로듀서, 콘솔 컨슈머라고 부릅니다.","console-producer-실습#Console Producer 실습":"토픽 topic1 로 프로듀서 기동합니다. docker를 새로 띄워서 topic 이 만들어져 있지 않은 상태라면 아래 프로듀서가 topic에 데이터를 보내면 토픽이 생성됩니다.\n$ kafka-console-producer --topic topic1 --broker-list kafka:9092\n이 상태에서 데이터를 전송하면, 토픽을 외부에서 만들지 않은채로 프로듀서로 데이터를 전송하면서 생성한 것에 대한 경고문구가 나타납니다. 에러는 아니기에 장애가 나거나 하는 것은 아니지만, 조심해서 사용해야합니다.\n[2024-05-30 21:58:08,575] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 4 : {topic1=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)\n실무에서는 이렇게 쓰는 편은 아니고, 동적 생성을 막는 프로퍼티도 따로 있기 때문에 이런 프로퍼티들을 적용하기도 합니다.위와 같이 명령할수도 있고 아래와 같이 브로커리스트, 프로듀서 프로퍼티를 추가해서 프로듀서를 기동하는 것 역시 가능합니다.\n$ kafka-console-producer --topic\ntopic1 --broker-list kafka:9092 --producer-property acks=all\n이번에는 key, value 로 데이터를 생산해봅니다. key,value 형태로 데이터를 보내기 위해서는 key.separator 라는 속성이 필요하며, 만약 key.separator 를 : 으로 지정했을때 name:트럼프 라고 데이터를 전송하면 카프카는 key = name, value = 트럼프 와 같은 형식으로 데이터를 인식하며 생산합니다. 아래는 그 예제입니다.\n$ kafka-console-producer --topic topic1 --broker-list kafka:9092 --property parse.key=true --property key.separator=:\n>name:트럼프","카프카-컨슈머-cli#카프카 컨슈머 CLI":"","단순-consumer-예제#단순 Consumer 예제":"먼저 카프카 도커 컨테이너의 bash 로 진입합니다.\n$ docker-compose exec kafka bash\n데이터의 생산,소비를 위해 아래의 명령어를 입력합니다. 파티션을 3 으로 지정했고 토픽 명은 topic2 로 지정했습니다.\n$ kafka-topics --bootstrap-server localhost:9092 --topic topic2 --create --partitions 3\nCreated topic topic2.\n방금 생성한 토픽인 topic2 에 대해서 컨슈머를 기동합니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic2\n새로 터미널 창을 열어서 도커 컨테이너의 bash 로 진입합니다.\n$ docker-compose exec kafka bash\n아래와 같이 프로듀서를 기동하고 데이터 2건을 생산합니다.\n$ kafka-console-producer --boorap-server localhost:9092 --producer-property partitioner.class=org.apache.kafka.clients.producer.RoundRobinPartitioner --topic topic2\n>productId:1\n>productId:2\n컨슈머측을 열어둔 터미널을 확인해보면 아래와 같이 데이터가 수신되었음을 확인 가능합니다.\nproductId:1\nproductId:2\nCtrl + C 를 입력해서 컨슈머에서 빠져나온 후 다시 컨슈머를 실행해보면 아무 데이터도 안옵니다. 기본 수신 정책이 최근의 값만 받도록 하는 속성으로 설정되어 있기 때문입니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic2\n이번에는 콘솔 컨슈머를 닫았다가 다시 실행할때 데이터를 처음부터 소비해봅니다. --from-beginning 을 주면 처음부터 데이터를 읽어들이게 됩니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic2 --from-beginning\nproductId:2\nproductId:1\n아래는 key, value, timestamp 를 받는 예제입니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic2 --formatter kafka.tools.DefaultMessageFormatter --property print.timestamp=true --property print.key=true --property print.value=true --property print.partition=true --from-beginning","consumer-group-1#Consumer Group (1)":"파티션 3개, 레플리케이션 1을 지정해서 토픽 topic3 을 생성합니다.\n$ kafka-topics --create --topic t\nopic3 --bootstrap-server kafka:9092 --partitions 3 --repl\nication-factor 1\nCreated topic topic3.\n컨슈머를 기동합니다. 컨슈머 그룹명을 created-products 로 지정해서 기동했습니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic3 --group created-products\n프로듀서를 띄웁니다. Partitioner 를 RoundRobin 으로 지정했고, topic 은 topic3 에 생산합니다.\n$ kafka-console-producer --bootst\nrap-server localhost:9092 --producer-property partitioner\n.class=org.apache.kafka.clients.producer.RoundRobinPartitioner --topic topic3\n컨슈머를 3개 더 기동합니다. 파티션 갯수 보다 컨슈머가 더 많을 때 어떻게 되는지 직접 확인해보기 위해서입니다. 아래 명령어를 터미널 3개에 모두 컨슈머를 띄운후 실행합니다.\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic3 --group created-products\n프로듀서측 터미널에서 데이터를 전송해봅니다.\n>productId:1\n>productId:2\n>productId:3\n>productId:4\n컨슈머 측에서는 아래와 같이 나타납니다.\n# 첫번째로 띄운 컨슈머 \nproductId:2\n# 두번째로 띄운 컨슈머\nproductId:1\nproductId:4\n# 세번째로 띄운 컨슈머\n# 네번째로 띄운 컨슈머\nproductId:3\n세번째로 띄운 컨슈머는 데이터를 받지 못하는 상황이 발생했습니다.","consumer-group-2#Consumer Group (2)":"도커 컨테이너에 bash 로 접속 후 아래의 명령어를 실행하면 컨슈머 그룹을 리스트해볼 수 있습니다.\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --list\ncreated-products\ndescribe\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group created-products\nGROUP            TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID\ncreated-products topic3          1          2               2               0               console-consumer-0ca87f5b-45df-4a86-ae29-f5bc667f24b2 /172.19.0.3     console-consumer\ncreated-products topic3          0          1               1               0\n  console-consumer-0aa38bf9-3491-4ecc-b7dc-74fe243ea41e /172.19.0.3     console-consumer\ncreated-products topic3          2          1               1   \nLEO, LAG"}},"/kafka-cli-examples/lag-leo-example":{"title":"Lag Leo Example","data":{"":"토픽생성\n$ kafka-topics --create --topic topic3 --bootstrap-server kafka:9092 --partitions 3 --replication-factor 1\n토픽 Listen (컨슈머 그룹명 : created-products)\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic topic3 --group created-products\n컨슈머 그룹 리스트 확인 (새로운 터미널 창에서)\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --list\ncreated-products\n컨슈머들 상태 확인 (--describe)\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group created-products\nGROUP            TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID\n... 결과값은 캡처로 대체함 (가독성이 떨어져서)\n콘솔 프로듀서 구동\n$ kafka-console-producer --bootstrap-server localhost:9092 --producer-property partitioner.class=org.apache.kafka.clients.producer.RoundRobinPartitioner --topic topic3\n데이터 입력\n>10\n>11\n>12\n>13\n>1111\n>111111\n>11111\n>1\n>1\n>1\n>1\n>1\n>1\n>1\n>\n>1\n>1\n>\n>1\n>1\n>1\n>1\n>1\n>1\n>1\n>1\n>\n>1\n>1\n>\nLAG 이 늘어나는 상황 확인해보기\npartition 은 3개인데 consumer 는 1개 구동 중인 상황\n프로듀서에서 넣어주는 데이터의 양이 컨슈머에서 읽어들이는 데이터의 양보다 많을 경우 LAG 값이 커지는 현상 확인\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group created-products\n데이터의 소비를 모두 하지 못한 상황에서는 LAG 항목에 1 이상의 값이 나타나게 됩니다.컨슈머가 데이터를 모두 소모하고 나면 LAG 은 다시 0 으로 돌아옵니다.","offset#Offset":"Log-End-Offset (LEO) : Partition 데이터의 끝을 의미합니다. (생성되는 데이터의 가장 최신데이터)\nCurrent Offset : Consumer 가 어디까지 메시지를 읽었는지를 의미합니다.\nCommit Offset : Consumer 가 어디까지 커밋을 했는지를 의미합니다. Consumer 에서 offset 을 처리했다는 Offset Commit 을 요청하면 업데이트 됩니다.\nLAG 란?\nLEO 와 Current Offset 의 차이를 의미합니다.\nLAG 값이 0 보다 크다는 것은 그 만큼 컨슈머가 처리를 못했다는 의미입니다."}},"/kafka-concepts":{"title":"Kafka Concepts","data":{"":"카프카 기본 개념들을 정리합니다."}},"/kafka-concepts/kafka-basic":{"title":"Kafka Basic","data":{"kafka-의-주요-개념들#kafka 의 주요 개념들":"출처 : https://www.educba.com/kafka-replication-factor/\n출처 : https://medium.com/@_amanarora/replication-in-kafka-58b39e91b64e","kafka-의-주요-특징#Kafka 의 주요 특징":"RabbitMQ, ActiveMQ 는 흔히 메시지 큐 인프라라고 부릅니다. 카프카의 경우에는 데이터 플랫폼이라고 부릅니다. RabbitMQ, ActiveMQ 의 경우 push model 을 채택하고 있지만, 카프카는 Publish/Subscribe 모델을 채택하고 있습니다.분산시스템\n여러 브로커로 분산된 분산 시스템입니다.\nThroughput (처리량)\n실시간처리를 가능하게 해주며, 토픽을 여러 파티션으로 나눠서 처리할 수 있기 때문에 트래픽이 적은 시점에는 적은 수의 컨슈머로 트래픽을 처리하고 트래픽이 많아지면 컨슈머의 수를 늘려서 데이터를 처리할 수 있도록 유연함을 제공합니다.\nScalability (영속성)\n수신한 데이터를 디스크에 저장합니다. 따라서 임의의 시점에 데이터를 읽을 수 있습니다.\nReliability (신뢰성)\n메시지 전달을 보증하는 방식으로 통신을 합니다.\n예를 들어서 Producer Acknowledgement 를 1 로 설정하면 Leader Replica 에 데이터가 전달 되었는지를 확인 후에 Ack 를 반환하는 경우를 예로 들 수 있습니다.\nHigh Availability (고가용성)\n여러 노드 들로 분산된 처리를 하며, 리더 브로커가 유실되더라도 나머지 브로커 중 하나가 리더 브로커 역할을 할 수 있습니다. 이 때 팔로워 브로커 들에 데이터가 복제가 이뤄지고 있도록 하는 메커니즘이 되어 있기 때문에 여러 노드에 걸쳐서 접근 가능함(Availability) 를 제공할 수 있게 됩니다.","message-format#Message Format":"Kafka 의 Message Format 입니다. 가장 기본적인 방식은 Key, Value 를 binary type 으로 직렬화/역직렬화 하는 방식입니다.조금 더 복잡한 방식으로 진화하거나 서비스의 변경사항이 유연하게 반영되도록 할 경우에는 String, int, Avro, Protobuf 등과 같은 다양한 방식으로 데이터를 직렬화/역직렬화 합니다.Avro 는 Schema Registry 가 운영되어야 사용 가능한 방식이며, 데이터의 변경사항에 조금 더 유연한 방식이지만 데이터 형식으로 시간타입등이 정수형으로 사용되어야 한다던가 하는 불편함이 있습니다. 카프카를 카프카 커넥트, 카프카 스트림즈 등 다양한 방식으로 사용하는 회사에서 사용되는 데이터 포맷 방식입니다.\nKafka Connect Avro Converter 카프카 스트림즈 예제 2\navro-kotlin/avro4k","컨슈머-측면--pull-model-vs-push-model#컨슈머 측면 : Pull Model vs Push Model":"","pull-model#Pull Model":"카프카의 컨슈머는 topic 으로부터 데이터를 읽어들입니다. 브로커가 데이터를 Push 한 것을 받아들이는 방식이 아닙니다. 컨슈머가 장애 발생 또는 유지보수를 위해 정지했을 경우 브로커에게 미치는 영향이 적다는 것이 pull model 의 장점입니다.","push-model#Push Model":"RabbitMQ 와 같은 메시지 큐 시스템에서 사용되는 컨슈머 애플리케이션의 경우 Push Model 방식의 컨슈머입니다. 단건 데이터의 속도가 빠를 경우 여기에 대해 동시성 처리를 잘 해줘야 한다는 어려움이 존재합니다.","토픽#토픽":"메시지를 적재하거나 구독할 수 있는 하나의 메시지 대기열 입니다. 데이터를 읽었던 위치는 __consumer_offset 이라고 하는 카프카 내부의 토픽에 저장됩니다. 카프카는 데이터를 영속화 할 수 있습니다.토픽은 파티션 1개로만 운영할 수도 있고 여러개의 파티션으로 나누어 운영할 수 도 있습니다. 파티션을 1개로 구성할 경우 컨슈머 랙 증상이 발생할 수 있기 때문에 파티션을 여러개로 구성해서 사용하는 경우가 많습니다.일반적으로는 토픽 하나에 파티션을 여러 개 두어서 컨슈머 랙 증상을 방지하는 편입니다.","partition-rf-isr-leader-partition#Partition, RF, ISR, Leader Partition":"","partition#Partition":"파티션은 토픽을 여러개로 나누었을 때 나누어진 개별 영역을 파티션이라고 합니다.하나의 토픽은 여러개의 파티션으로 분리될 수 있습니다. 파티션은 데이터가 저장될 위치를 의미합니다. 즉, 데이터에 대해 파티셔닝 알고리즘을 적용해서 특정 파티션으로만 데이터가 전달될 수 있도록 파티션의 위치를 지정해주는 것을 파티셔닝이라고 합니다.파티션이 많으면 성능은 향상되지만 절대적이지는 않습니다. 브로커 성능에는 한계가 있기 때문입니다.파티션은 프로듀서가 보내는 메시지의 메시지 키 값에 의해 파티션이 선택됩니다. 이 메시지 키 값을 지정하지 않고 메시지를 전송할 경우 내부적으로 라운드 로빈 방식으로 파티션을 선택해서 데이터를 전송하게 됩니다.\nKey 가 존재할 경우 : 키를 Hash 값으로 변환 후 특정 파티션을 선택. 항상 같은 파티션이 선택 됨\nKey 를 지정하지 않으면 : Round Robin 방식으로 파티션을 선택\n위의 그림은 메시지의 KEY:VALUE 가 아래와 같이 구성되었을 때 어떻게 파티션이 나타내는지를 표현한 그림입니다.\n1:안녕하세요\nKEY 가 1일 때는 3으로 나눈 나머지가 1이기에 파티션 1번으로 분배\n2:누구시죠?\nKEY 가 2일 때는 3으로 나눈 나머지가 2이기에 파티션 2번으로 분배\n3: 님은 누구신데요?\nKEY 가 3일 때는 3으로 나눈 나머지가 0이기에 파티션 0번으로 분배","rf-replication-factor#RF (Replication Factor)":"하나의 파티션은 1개 이상의 복제본 (Replica) 을 가질 수 있습니다. RF (Replication Factor) 는 복제본의 갯수를 의미합니다. RF가 1보다 크면 클수록 가용성(Availability)이 높아진다고 할 수 있습니다. 물론, 이때 브로커 갯수가 충분해야 합니다.RF 가 너무 크면 저장공간이 낭비된다는 단점이 있습니다. Produce 시에도 지연시간이 길어집니다. 복제해줘야 하는 노드가 많아지기 때문입니다.일반적으로 Replica 의 갯수는 Broker 의 갯수보다 적은 것이 권장됩니다. 그래야 안정적이고 성능 부하가 없습니다.아래의 그림들을 참고해주시기 바랍니다.\n출처 : https://www.educba.com/kafka-replication-factor/\n출처 : https://medium.com/@_amanarora/replication-in-kafka-58b39e91b64e","isr-in-sync-replica#ISR (In-Sync Replica)":"Replica 중 Sync 를 맞출 Replica 의 그룹을 ISR (In-Sync Replica) 그룹이라고 이야기합니다.Partition 의 복제본이 많아지면 가용성(Availability)가 늘어납니다. 그리고 'Produce' 시에도 복제해야 할 데이터가 늘어납니다. 이렇게 되면 Produce 시의 지연 시간이 길어질 수 있다는 단점이 생깁니다.\nISR 그룹에 많은 파티션을 포함하고 있으면\nProduce 신뢰성/가용성 향상\nbut, 지연시간 증가\nISR 그룹에 적은 파티션을 포함하고 있으면\nProduce 신뢰성/가용성 하락\nbut, 지연시간 감소\n\"적절하게 토픽에 Produce 되었다\"\n→ \"토픽 내의 파티션들의 모든 ISR 그룹에 복제가 잘 이뤄졌다.\"\nProduce 가 되었다는 의미에는 꼭 ISR 그룹에 복제하는 작업도 모두 완료되었다는 의미가 내포되어 있다는 사실을 기억해야 합니다.","leader-partition#Leader Partition":"복제된 Partition 들 중 하나는 Leader 로 선출됩니다. 기본적으로 Producer 는 Leader 파티션이 포함된 Broker 에 메시지를 전송합니다. 이후 broker 는 나머지 Partition 들에 메시지를 복제합니다.Consumer 역시 Leader Partition 이 포함되어 있는 Broker 로부터 데이터를 읽습니다. \n카프카 2.4 부터는 leader 가 아닌 가장 가까운 broker 로부터 데이터를 읽도록 설정하는 것이 가능해졌습니다.","메시지-프로듀서#메시지, 프로듀서":"메시지토픽에 적재되는 개별 데이터를 메시지라고 합니다. 메시지는 key, value, timestamp 로 구성됩니다. 프로듀서토픽에 데이터를 적재하는 역할을 합니다.프로듀서는 여러가지 언어로 작성 가능합니다.","producer-acknowledgement-acks#Producer Acknowledgement (Acks)":"acks = 0\nProducer 가 메시지를 보낼 때 Ack 를 기다리지 않고 보내는 방식입니다.\n데이터가 손실될 수 있습니다.\nacks = 1\nLeader Replica 에 데이터가 전달되면 Ack 를 반환하는 방식입니다.\n일반적으로 현업에서는 Ack = 1 을 많이 쓴다고 합니다. 팔로워 들에게 복제가 안됐을 가능성이 있다고 생각을 할 수 도 있지만, 결과적으로는 카프카 내에서 내부적인 가정으로 복제를 해낸다는 가정으로 설정합니다.\nacks = all\nLeader + 모든 ISR 에 데이터가 복제가 되면 Ack 를 반환합니다.\n가장 안전한 방식이지만, 성능상에 이슈가 존재합니다.","컨슈머-컨슈머-랙-lag-컨슈머-그룹-컨슈머-오프셋#컨슈머, 컨슈머 랙 (LAG), 컨슈머 그룹, 컨슈머 오프셋":"","컨슈머#컨슈머":"컨슈머는 토픽을 구독해서 메시지를 읽어들이는 역할을 수행합니다. 보통 컨슈머의 개수는 파티션의 개수에 맞춰서 띄웁니다.","컨슈머-랙#컨슈머 랙":"컨슈머는 토픽을 구독해서 메시지를 읽어들입니다.  그런데 프로듀서가 메시지를 발행하는 속도에 비해 컨슈머가 메시지를 읽어서 처리하는 속도가 느릴 경우 점점 컨슈머의 오프셋이 가장 최신 오프셋으로부터 멀어지게 됩니다. 이렇게 컨슈머의 읽기 속도가 메시지 발급속도를 따라가지 못하는 현상을 \"컨슈머 랙(Consumer Lag)\" 이라고 부릅니다.컨슈머 랙 증상은 토픽을 여러 개의 파티션으로 구성하고 각각의 파티션을 구독하는 컨슈머들을 파티션 갯수만큼 띄우는 것으로 해결이 가능합니다.","컨슈머-그룹#컨슈머 그룹":"보통 토픽을 파티션 1개로만 운영하는 경우가 없기때문에 여러개의 파티션으로 구성하는데, 이렇게 파티션을 여러개로 나누어 둔 경우 컨슈머 역시 파티션 갯수에 맞춰서 띄웁니다. 그리고 띄운 컨슈머들을 하나의 그룹으로 묶어서 하나의 그룹으로 인식하는데 이것을 컨슈머 그룹이라고 합니다..만약 토픽 하나에 대한 파티션 개수보다 컨슈머 그룹내의 컨슈머 개수가 더 많다면 어떻게 될까요? 이런 경우 놀고 있는(유휴(Idle)) 상태의 컨슈머가 생기게 됩니다. 장애로 이어지지는 않지만 자원 낭비가 생기게 됩니다.\n여러 개의 파티션으로 나눌 경우 각 파티션을 바라봐야 할 컨슈머 개수도 파티션의 개수에 맞춰서 운영합니다. 그런데 파티션의 개수보다 컨슈머의 수가 더 많을 경우 일부 컨슈머는 파티션을 할당받지 못하고 대기 상태가 됩니다. 위의 그림에서는 초록색 배경으로 표시한 컨슈머가 유휴상태에 진입했습니다.","컨슈머-오프셋-consumer-offset#컨슈머 오프셋 (Consumer Offset)":"","__consumer_offset#__consumer_offset":"Kafka 는 Consumer Group 이 어떤 파티션의 어느 offset 까지 읽었는지 offset 정보를 저장합니다. offset 정보는 __consumer_offset 이라는 topic 에 저장됩니다. Offset 이 커밋되는 방식은 아래와 같이 3종류이며 실무에서 많이 사용되는 방식은 At least once 입니다.","컨슈머-오프셋-consumer-offset-커밋-방식들#컨슈머 오프셋 (Consumer Offset) 커밋 방식들":"","at-least-once#At Least Once":"실무에서 가장 많이 쓰는 방식입니다.\n적어도 1회는 전달되며 메시지는 중복될 수는 있어도 상실되지는 않습니다.\n재전송시도를 하며, 중복된 데이터를 삭제 하지 않습니다.\nIdempotent (멱등성) 해야 합니다. (중복된 메시지를 처리하는 것이 시스템에 영향을 미치지 않아야 합니다.)","at-most-once#At Most Once":"1 회는 전달을 시도해보는 방식입니다.\n메시지는 중복되지 않지만 상실될 수 있습니다.\n재전송 시도를 안하고, 중복역시 삭제하지 않습니다.\n예를 들면 미디어 스트리밍 처럼 실시간 중계를 할 경우에 선택할 수 있는 방식입니다.","exactly-once#Exactly Once":"메시지를 정확히 1회만 전달합니다.\n모든 파티션에 복제를 해야 하기에 성능은 좋지 않습니다.\n이래 저래 검색을 해본 결과 현업에서는 데이터 복제 시의 장애가 날 것이라는 가정 없이 내부적으로 복제를 할 것이라는 전제 하에 At Least Once 를 선택한다고 합니다. 어차피 리더 파티션이 데이터를 받았다면, 그 이후의 복제 실패 상황에 대해 다른 파티션으로의 복제작업을 재개하는 작업 등은 L4 레벨에서의 메커니즘으로 간주하는 듯 보입니다.추측을 해보면, 대부분의 경우 애플리케이션 레벨에서 특정 키값이 있는지 없는지 체크하는 로직을 정의해두는 것으로 보입니다.","순서가-중요한-메시지일-경우#순서가 중요한 메시지일 경우":"","1-인프라-레벨에서-해결하는-방식#1) 인프라 레벨에서 해결하는 방식":"순차적인 메시지 처리를 하게끔 해야 하는 경우가 있습니다. 이런 경우 어떻게 하면 문제를 해결할 수 있는지를 정리해봅니다.토픽을 여러 개의 파티션으로 파티셔닝하면 메시지가 순차적으로 처리는 것을 보장하지 못하게 됩니다. 예를 들어서 주문완료 → 결제완료 → 상품준비중 의 순서로 메시지를 보내야 하는 경우가 있습니다.만약 파티션 알고리즘에 따라 처리하거나, 기본 설정인 라운드 로빈 방식으로 처리할 경우 주문완료 메시지는 파티션 1에, 결제완료는 파티션 2에, 상품 준비중 이벤트는 파티션1에 쌓이게 되어서 메시지가 순차적으로 전달되지 않을 수 있습니다.이런 경우 특정 상품을 장바구니에서 주문/결제 하는 기능에 대해서는 특정 파티션을 선택해서 메시지를 전송하게끔 하는 것으로 이런 문제를 해결 가능합니다.","2--애플리케이션-레벨에서-해결하는-방식-중요#2)  애플리케이션 레벨에서 해결하는 방식 (중요)":"메시지의 키값을 시간 순으로 정렬 할 수 있는 키값으로 지정해서 카프카에 전송하는 방식입니다. 메시지의 키값을 시간순으로 정렬할 수 있도록 구성했기 때문에 DB 등에서 다시 불러올 때는 가장 오래된 메시지부터 읽어들일 수 있습니다.\n참고 : 아파치 카프카 애플리케이션 프로그래밍 with 자바\n이렇게 하면 컨슈머측에서 데이터를 읽어들일때 느려질 것이라고 추측하는 분들도 계실 수 있습니다. 하지만, 카프카의 컨슈머는 위에서 설명했듯 pull model 을 채택하고 있습니다. 컨슈머에 부하가 걸리는 일은 없고 다만 LAG 이 발생할 수 있다는 점만 존재합니다.LAG 이 발생하는 경우에 대한 문제점은 파티션의 범위를 크게 잡아서 컨슈머를 더 늘릴 수 있도록 구성하는 것으로 해결하고, 트래픽이 적을때는 컨슈머를 줄이는 것으로 해결이 가능합니다.","카프카-브로커#카프카 브로커":"카프카 브로커는 토픽들과 파티션들을 가지고 운영하고 있는 하나의 물리적인 서버를 의미합니다.","카프카-브로커-클러스터링#카프카 브로커 클러스터링":"몽고DB의 레플리카셋, 샤드 클러스터를 구성해보셨거나 k8s 앱을 작성해보신 분들이라면 클러스터링이라는 것이 무엇을 의미하는지 아실 겁니다. 카프카 브로커 역시 클러스터링이 가능합니다.위의 그림에서 보듯 주키퍼(zookeeper)를 통해서 브로커들의 상태를 관리하고, 리더파티션 선출, 메타데이터 관리 등의 역할을 합니다. 주키퍼(zookeeper) 역시 클러스터링이 가능합니다.","카프카-브로커-장애-발생시-리더-파티션-재선출#카프카 브로커 장애 발생시 리더 파티션 재선출":"위의 그림에서는 1번 브로커 에서 장애가 생겼습니다. 브로커 1 에는 파티션 1을 리더 파티션으로 운영되고 있었습니다. 이렇게 장애가 생긴 경우 주키퍼(zookeeper)가 브로커들의 상태를 체크하고 있다가 장애를 파악하면 리더 파티션을 투표를 통해서 선출하게 되는데요. 위의 그림에서는 2번 브로커 내의 1번 파티션이 리더로 선출된 것을 확인 가능합니다.참고로 주키퍼(zookeeper) 역시 클러스터링이 가능합니다.","가용성availability#가용성(Availability)":"가용성(Availability) 라는 단어는 Available 해야 한다는 성격을 의미합니다. 어떤 노드나 커넥션 포인트가 계속해서 접근이 가능한 성격을 띄어야 한다는 이야기 입니다. 만약 노드 하나가 통신이 불가능한 상황이 되었을 때 같은 그룹 내의 다른 노드가 그 역할을 대신할 수 있어야 하는데, 이와 같은 용어를 가용성(Availability) 라고 부릅니다.","rabbitmq#RabbitMQ":"RabbitMQ 의 경우 데이터를 그대로 보냅니다. 전송 레벨에서의 commit, rollback 이 없습니다. 따라서 전송실패나 예외 상황에 대한 예외 처리를 직접 작성해줘야 합니다. 캐싱전략을 잘짜거나 등등 이런 전략을 잘 구현한다면 예외 상황에 대한 대응이 가능해집니다.컨슈머 입장에서는 Push 모델 방식으로 데이터를 받습니다. 따라서 컨슈머 측에서 부하를 처리하기 쉽지 않습니다.","통신레벨의-트랜잭션-비즈니스-트랜잭션#통신레벨의 트랜잭션, 비즈니스 트랜잭션":"카프카의 경우 전송 레벨에서의 commit, rollback 이 지원됩니다. 메시지 큐 레벨에서의 메시지 트랜잭션이라는 것이 존재합니다. 그런데, 간혹 이것을 비즈니스 실패시의 실패와 혼동해서 사용할 경우가 가끔 있는데, 단순한 전송 기능의 실패와 비즈니스 로직 실패와는 구별해서 사용해야 합니다.","pull-모델의-장점#pull 모델의 장점":"카프카의 컨슈머 입장에서는 Pull 모델 방식으로 데이터를 구독합니다. 따라서 Consumer 의 부하 없이 데이터를 처리하는 것이 가능합니다. 다만 LAG 이 발생할 경우 별도의 처리가 필요합니다.","kafka-도입에-대한-개인적인-의견#Kafka 도입에 대한 개인적인 의견":"토픽을 어떻게 설계할지 파티션은 몇개로 잡을지, 파티셔닝 알고리즘은 뭘로 할지 부터 모니터링은 뭘로 할지 등을 세부적으로 결정해야 합니다. 어떻게 하다보니 간접적으로 들은 이야기로는 일반적으로 현업에서 카프카 도입에 5개월을 잡고 프로젝트로 진행합니다. 저는 직접 카프카를 도입한 경우는 없지만, 대부분 RabbitMQ 레벨에서 해결되는 케이스였습니다. 이 문서는 제가 스터디를 위해 열심히 정리했지만요.대용량 데이터 처리시 k8s 보다는 카프카가 클러스터링이 용이하고 편리하다면 인하우스 툴로 사용할수 있겠지만, 실무에서 사용할 경우 비즈니스 적으로 신뢰성이 보장되어야 할 경우 인프라 쪽으로 제대로 설계해서 적용해야 할 것 같습니다.이 외에도 통신 레벨의 트랜잭션에 비즈니스 트랜잭션을 함께 사용(KafkaListener 내에 DB 트랜잭션, 커밋 연산)해서 장애의 추적이 어렵게 되는 케이스는 지양해야하 것 같습니다. 비동기적인 통신을 위해 Producer, Consumer 로 분리해서 Pull 모델을 사용하지만, 결국은 Consumer 측의 KafkaListener 측에서는 동기적인 처리를 하게되는 케이스가 되는 설계이기에 이 경우 컨슈머 측의 기능에 대해서 어떻게 해야 비동기처리를 할지 등을 결정해야 실무에서 발생하는 복구하기 쉽지 않은 장애가 발생하지 않을 것으로 보입니다.이 외에도 카프카를 굳이 사용하지 말아야 하는 케이스도 많습니다.\n얘를 들면, 대용량 알림톡 등의 경우에는 배치를 사용해도 될것 같습니다. 카프카의 성격과는 맞지 않으며, 알림톡을 보냈는지를 기록하는 것이 트랜잭션이 되어야 하는데, 통신레벨의 트랜잭션과 비즈니스 레벨의 트랜잭션을 분리하기 어려워보입니다. 여러 가지를 모두 배제하더라도 알림톡 발송에 카프카를 사용하려는 발상 자체도 조금은 닭잡는데 소잡는 칼을 쓰는 것 같은 느낌도 들긴 합니다."}},"/kafka-java-examples":{"title":"Kafka Java Examples","data":{"plain-java-example#Plain Java Example":"기본적인 예제를 다룹니다.\nProducer\nProducer with Callback\nProducer with key\nConsumer\nConsumer with Graceful Shutdown"}},"/kafka-multi-module-example":{"title":"Kafka Multi Module Example","data":{"카프카-멀티모듈-예제#카프카 멀티모듈 예제":"카프카로 멀티모듈을 구성할 경우 어떻게 할지에 대한 간단한 예제, 컨셉들을 정리\nSpring Kafka, Kotlin, Gradle Kotlin DSL","참고자료#참고자료":"여기서 작성한 코드의 전반적인 컨셉은 아래 예제를 참고해서 작성해두었던 예제입니다.\nMicroservices: Clean Architecure, DDD, SAGA, Outbox & Kafka"}},"/search-list":{"title":"Search List","data":{"주요-자료-조사#주요 자료 조사":"카프카 파티션의 이해\n카프카 클러스터에 적당한 토픽, 파티션의 개수는?"}},"/stream-processing-example-1":{"title":"Stream Processing Example 1","data":{"":"Producer : Kafka\nConsumer : Spark"}},"/stream-processing-example-1/api-key-creation":{"title":"API Key Creation","data":{"api-키-발급--개발가이드-문서-파악#API 키 발급 & 개발가이드 문서 파악":"","kakao-api-키-발급#Kakao API 키 발급":"https://developers.kakao.com/ 에 방문합니다. \"내 애플리케이션\" 메뉴를 클릭합니다.+ 애플리케이션 추가하기 버튼을 클릭합니다.앱 이름, 회사명, 카테고리를 입력해줍니다. 그리고 저장합니다.애플리케이션이 추가된 모습입니다.앱 키를 확인해보러 갑니다.REST API 키를 복사해주시면 됩니다.","naver-api-키-발급#Naver API 키 발급":"https://developers.naver.com/main/ 에 방문해서 Appliation → 애플리케이션 등록 버튼을 클릭합니다.애플리케이션을 등록하면서 아래와 같이 선택해줍니다.사용 API\n\"검색\" 을 선택했습니다.\nClient ID, Client Secret 키를 복사해두시면 됩니다.","kakao-api--도서-검색-기능#Kakao API > 도서 검색 기능":"제품 버튼을 클릭합니다.아래로 스크롤 하면 검색버튼이 나타나는데 이 버튼을 클릭해줍니다.문서보기 버튼을 클릭합니다.나타나는 화면에서 REST API 버튼을 클릭합니다.","kakao-api-의-api-key-헤더-형식#Kakao API 의 API KEY 헤더 형식":"Kakao API 에서 사용할 수 있는 API key 의 헤더 형식에 대해 나오는데, 이 방식대로 요청하면 요청이 이뤄지게 됩니다. 요청 형식을 코드에 복사해두거나 별도의 텍스트 파일에 복사해둡니다.","naver-api--도서-검색-기능#Naver API > 도서 검색 기능":"https://developers.naver.com/main/ 에 접속해서 Products 메뉴에 마우스를 올려두면 서브 메뉴가 나타나는데 이 중 검색 을 선택합니다.개발 가이드 보기 버튼을 클릭합니다.왼쪽 사이드 메뉴에서 \"책\"을 선택합니다.","naver-api-의-api-key-요청-형식#Naver API 의 API Key 요청 형식":"아래로 스크롤을 하면 아래와 같은 내용이 나옵니다.\n참고사항\nAPI를 요청할 때 다음 예와 같이 HTTP 요청 헤더에 클라이언트 아이디와 클라이언트 시크릿을 추가해야 합니다.\n> GET /v1/search/book.xml?query=%EC%A3%BC%EC%8B%9D&display=10&start=1 HTTP/1.1\n> Host: openapi.naver.com\n> User-Agent: curl/7.49.1\n> Accept: */*\n> X-Naver-Client-Id: {애플리케이션 등록 시 발급받은 클라이언트 아이디 값}\n> X-Naver-Client-Secret: {애플리케이션 등록 시 발급받은 클라이언트 시크릿 값}\n>","요청-예#요청 예":"curl \"https://openapi.naver.com/v1/search/book.xml?query=%EC%A3%BC%EC%8B%9D&display=10&start=1\" \\\n    -H \"X-Naver-Client-Id: {애플리케이션 등록 시 발급받은 클라이언트 아이디 값}\" \\\n    -H \"X-Naver-Client-Secret: {애플리케이션 등록 시 발급받은 클라이언트 시크릿 값}\" -v"}},"/stream-processing-example-1/what-to-do":{"title":"What to Do","data":{"생산자#생산자":"아래의 두 종류의 API 를 통해서 가져온 도서검색 결과를 Kafka 의 books 라는 토픽에 생산합니다.\nKakao 검색 API 내의 도서검색 기능\nNaver 검색 API 내의 도서검색 기능","소비자#소비자":"소비자에서는 가져온 도서 검색결과를 통해서 최고가, 최저가 등의 통계연산을 수행합니다."}}}